{"name":"Phantom","tagline":"Asynchronous type-safe Scala DSL for Cassandra","body":"phantom [![Build Status](https://travis-ci.org/newzly/phantom.png?branch=develop)](https://travis-ci.org/newzly/phantom)\r\n==============\r\nAsynchronous Scala DSL for Cassandra\r\n\r\n\r\nUsing phantom\r\n=============\r\n\r\nThe current version is: ```val phantomVersion = 0.2.0```.\r\nPhantom is published to Maven Central and it's actively and avidly developed.\r\n\r\n\r\nIntegrating phantom in your project\r\n===================================\r\n\r\nFor most things, all you need is ```phantom-dsl```. Read through for information on other modules.\r\n\r\n```scala\r\nlibraryDependencies ++= Seq(\r\n  \"com.newzly\"  %% \"phantom-dsl\"                   % phantomVersion\r\n)\r\n```\r\n\r\nThe full list of available modules is:\r\n\r\n```scala\r\nlibraryDependencies ++= Seq(\r\n  \"com.newzly\"  %% \"phantom-dsl\"                   % phantomVersion,\r\n  \"com.newzly\"  %% \"phantom-cassandra-unit\"        % phantomVersion,\r\n  \"com.newzly\"  %% \"phantom-example\"               % phantomVersion,\r\n  \"com.newzly\"  %% \"phantom-thrift\"                % phantomVersion,\r\n  \"com.newzly\"  %% \"phantom-test\"                  % phantomVersion,\r\n  \"com.newzly\"  %% \"phantom-finagle\"               % phantomVersion\r\n)\r\n```\r\n\r\n\r\nData modeling with phantom\r\n==========================\r\n  \r\n```scala\r\n\r\nimport java.util.{ UUID, Date }\r\nimport com.datastax.driver.core.Row\r\nimport com.newzly.phantom.sample.ExampleModel\r\nimport com.newzly.phantom.Implicits._\r\n\r\ncase class ExampleModel (\r\n  id: Int,\r\n  name: String,\r\n  props: Map[String, String],\r\n  timestamp: Int,\r\n  test: Option[Int]\r\n)\r\n\r\nsealed class ExampleRecord private() extends CassandraTable[ExampleRecord, ExampleModel] {\r\n\r\n  object id extends UUIDColumn(this) with PartitionKey[UUID]\r\n  object timestamp extends DateTimeColumn(this) with ClusteringOrder with Ascending\r\n  object name extends StringColumn(this)\r\n  object props extends MapColumn[ExampleRecord, ExampleModel, String, String](this)\r\n  object test extends OptionalIntColumn(this)\r\n\r\n  override def fromRow(row: Row): ExampleModel = {\r\n    ExampleModel(id(row), name(row), props(row), timestamp(row), test(row));\r\n  }\r\n}\r\n\r\n```\r\n\r\nQuerying with Phantom\r\n=====================\r\n\r\nThe query syntax is inspired by the Foursquare Rogue library and aims to replicate CQL 3 as much as possible.\r\n\r\nPhantom works with both Scala Futures and Twitter Futures. For the Twitter flavour, simply add the ```\"com.newzly  %% phantom-finagle % phantomVersion\"``` dependency.\r\n\r\n```scala\r\n\r\nobject ExampleRecord extends ExampleRecord {\r\n  override val tableName = \"examplerecord\"\r\n\r\n  // now define a session, a normal Datastax cluster connection\r\n  implicit val session = SomeCassandraClient.session;\r\n  \r\n  def getRecordsByName(name: String): Future[Seq[ExampleModel]] = {\r\n    ExampleRecord.select.where(_.name eqs name).fetch\r\n  }\r\n  \r\n  def getOneRecordByName(name: String, someId: UUID): Future[Option[ExampleModel]] = {\r\n    ExampleRecord.select.where(_.name eqs name).and(_.id eqs someId).one()\r\n  }\r\n}\r\n```\r\n\r\nPartial selects\r\n===============\r\n\r\nAll partial select queries will return Tuples and are therefore limited to 22 fields.\r\nThis will change in Scala 2.11 and phantom will be updated once cross version compilation is enabled.\r\n\r\n```scala\r\n  def getNameById(id: UUID): Future[Option[String]] = {\r\n    ExampleRecord.select(_.name).where(_.id eqs someId).one()\r\n  }\r\n  \r\n  def getNameAndPropsById(id: UUID): Future[Option(String, Map[String, String])] {\r\n    ExampleRecord.select(_.name, _.props).where(_.id eqs someId).one()\r\n  }\r\n```\r\n\r\nCollection operators\r\n====================\r\n\r\nphantom supports CQL 3 modify operations for CQL 3 collections: ```list, set, map```.\r\n\r\nIt works as you would expect it to:\r\n\r\nList operators: ```prepend, prependAll, append, appendAll, remove, removeAll```\r\n\r\n```scala\r\n\r\nExampleRecord.update.where(_.id eqs someId).modify(_.someList prepend someItem).future()\r\nExampleRecord.update.where(_.id eqs someId).modify(_.someList prependAll someItems).future()\r\n\r\nExampleRecord.update.where(_.id eqs someId).modify(_.someList append someItem).future()\r\nExampleRecord.update.where(_.id eqs someId).modify(_.someList appendAll someItems).future()\r\n\r\nExampleRecord.update.where(_.id eqs someId).modify(_.someList remove someItem).future()\r\nExampleRecord.update.where(_.id eqs someId).modify(_.someList removeAll someItems).future()\r\n\r\n```\r\n\r\nSet operators: ```append, appendAll, remove, removeAll```\r\nMap operators: ```put, putAll```\r\n\r\nFor working examples, see [ListOperatorsTest.scala](https://github.com/newzly/phantom/blob/develop/phantom-test/src/test/scala/com/newzly/phantom/dsl/crud/ListOperatorsTest.scala) and [MapOperationsTest.scala](https://github.com/newzly/phantom/blob/develop/phantom-test/src/test/scala/com/newzly/phantom/dsl/crud/MapOperationsTest.scala).\r\n\r\n\r\nAutomated schema generation\r\n===========================\r\n\r\nReplication strategies and more advanced features are not yet available in phantom, but CQL 3 Table schemas are  automatically generated from the Scala code. To create a schema in Cassandra from a table definition:\r\n\r\n```scala\r\n\r\nimport scala.concurrent.Await\r\nimport scala.concurrent.duration._\r\n\r\nAwait.result(ExampleRecord.create().future(), 5000 millis)\r\n```\r\n\r\nOf course, you don't have to block unless you want to.\r\n\r\n\r\nPartition tokens, token functions and paginated queries\r\n======================================================\r\n\r\n```scala\r\n\r\nimport scala.concurrent.Await\r\nimport scala.concurrent.duration._\r\nimport com.newzly.phantom.Implicits._\r\n\r\nsealed class ExampleRecord2 private() extends CassandraTable[ExampleRecord2, ExampleModel] with LongOrderKey[ExampleRecod2, ExampleRecord] {\r\n\r\n  object id extends UUIDColumn(this) with PartitionKey[UUID]\r\n  object timestamp extends DateTimeColumn(this)\r\n  object name extends StringColumn(this)\r\n  object props extends MapColumn[ExampleRecord2, ExampleRecord, String, String](this)\r\n  object test extends OptionalIntColumn(this)\r\n\r\n  override def fromRow(row: Row): ExampleModel = {\r\n    ExampleModel(id(row), name(row), props(row), timestamp(row), test(row));\r\n  }\r\n}\r\n\r\n\r\nval orderedResult = Await.result(Articles.select.where(_.id gtToken one.get.id ).fetch, 5000 millis)\r\n\r\n```\r\nFor more details on how to use Cassandra partition tokens, see [SkipRecordsByToken.scala]( https://github.com/newzly/phantom/blob/develop/phantom-test/src/test/scala/com/newzly/phantom/dsl/SkipRecordsByToken.scala)\r\n\r\n\r\nCassandra Time Series\r\n=====================\r\n\r\nphantom supports Cassandra Time Series with both ```java.util.Date``` and ```org.joda.time.DateTime ```. To use them, simply mixin ```com.newzly.phantom.keys.ClusteringOrder``` and either ```Ascending``` or ```Descending```.\r\n\r\nRestrictions are enforced at compile time.\r\n\r\n```scala\r\n\r\nimport com.newzly.phantom.Implicits._\r\n\r\nsealed class ExampleRecord3 private() extends CassandraTable[ExampleRecord3, ExampleModel] with LongOrderKey[ExampleRecod3, ExampleRecord] {\r\n\r\n  object id extends UUIDColumn(this) with PartitionKey[UUID]\r\n  object timestamp extends DateTimeColumn(this) with ClusteringOrder with Ascending\r\n  object name extends StringColumn(this)\r\n  object props extends MapColumn[ExampleRecord2, ExampleRecord, String, String](this)\r\n  object test extends OptionalIntColumn(this)\r\n\r\n  override def fromRow(row: Row): ExampleModel = {\r\n    ExampleModel(id(row), name(row), props(row), timestamp(row), test(row));\r\n  }\r\n}\r\n```\r\n\r\nAutomatic schema generation can do all the setup for you.\r\n\r\n\r\nComposite keys\r\n==============\r\nPhantom also supports using composite keys out of the box. The schema can once again by auto-generated.\r\n\r\nA table can have only one ```PartitionKey``` but several ```PrimaryKey``` definitions. Phantom will use these keys to build a composite value. Example scenario, with the composite key: ```(id, timestamp, name)```\r\n\r\n```scala\r\n\r\nimport org.joda.time.DateTime\r\nimport com.newzly.phantom.Implicits._\r\n\r\nsealed class ExampleRecord3 private() extends CassandraTable[ExampleRecord3, ExampleModel] with LongOrderKey[ExampleRecod3, ExampleRecord] {\r\n\r\n  object id extends UUIDColumn(this) with PartitionKey[UUID]\r\n  object timestamp extends DateTimeColumn(this) with PrimaryKey[DateTime]\r\n  object name extends StringColumn(this) with PrimaryKey[String]\r\n  object props extends MapColumn[ExampleRecord2, ExampleRecord, String, String](this)\r\n  object test extends OptionalIntColumn(this)\r\n\r\n  override def fromRow(row: Row): ExampleModel = {\r\n    ExampleModel(id(row), name(row), props(row), timestamp(row), test(row));\r\n  }\r\n}\r\n```\r\n\r\nCQL 3 index and non-primary index columns\r\n=========================================\r\n\r\nWhen you want to use a column in a ```where``` clause, you need an index on it. Cassandra data modeling is out of the scope of this writing, but phantom offers ```com.newzly.phantom.Keys.SecondaryKey``` to enable querying.\r\n\r\nThe CQL 3 schema for secondary indexes can also be auto-generated with ```ExampleRecord4.create()```.\r\n\r\n```scala\r\n\r\nimport org.joda.time.DateTime\r\nimport com.newzly.phantom.Implicits._\r\n\r\nsealed class ExampleRecord4 private() extends CassandraTable[ExampleRecord4, ExampleModel] with LongOrderKey[ExampleRecod4, ExampleRecord] {\r\n\r\n  object id extends UUIDColumn(this) with PartitionKey[UUID]\r\n  object timestamp extends DateTimeColumn(this) with SecondaryKey[DateTime]\r\n  object name extends StringColumn(this) with SecondaryKey[String]\r\n  object props extends MapColumn[ExampleRecord2, ExampleRecord, String, String](this)\r\n  object test extends OptionalIntColumn(this)\r\n\r\n  override def fromRow(row: Row): ExampleModel = {\r\n    ExampleModel(id(row), name(row), props(row), timestamp(row), test(row));\r\n  }\r\n}\r\n```\r\n\r\n\r\nAsynchronous iterators for large record sets\r\n============================================\r\n\r\nPhantom comes packed with CQL rows asynchronous lazy iterators to help you deal with billions of records.\r\nphantom iterators are based on Play iterators with very lightweight integration.\r\n\r\nThe functionality is identical with respect to asyncrhonous, lazy behaviour and available methods.\r\nFor more on this, see this [Play tutorial](\r\nhttp://mandubian.com/2012/08/27/understanding-play2-iteratees-for-normal-humans/)\r\n\r\n\r\nUsage is trivial:\r\n\r\n```scala\r\n\r\nimport scala.concurrent.Await\r\nimport scala.concurrent.duration._\r\nimport com.newzly.phantom.Implicits._\r\n\r\nval enumerator = Await.result(ExampleRecord.select.where(_.timestamp gtToken someTimestamp).fetchEnumerator(), 5000 millis)\r\n\r\n```\r\n\r\nBatch statements\r\n================\r\n\r\nphantom also brrings in support for batch statements. To use them, see [IterateeBigTest.scala]( https://github.com/newzly/phantom/blob/develop/phantom-test/src/test/scala/com/newzly/phantom/iteratee/IterateeBigTest.scala)\r\n\r\nWe have tested with 10,000 statements per batch, and 1000 batches processed simulatenously. Before you run the test, beware that it takes ~40 minutes.\r\n\r\nBatches use lazy iterators and daisy chain them to offer thread safe behaviour. They are not memory intensive and you can expect consistent processing speed even with 1 000 000 statements per batch.\r\n\r\n\r\nThrift integration\r\n==================\r\n\r\nWe use Apache Thrift extensively for our backend services. ```phantom``` is very easy to integrate with Thrift models and uses ```Twitter Scrooge``` to compile them. Thrift integration is optional and available via ```\"com.newzly\" %% \"phantom-thrift\"  % phantomVersion```.\r\n\r\n```thrift\r\nnamespace java com.newzly.phantom.sample.ExampleModel\r\n\r\nstuct ExampleModel {\r\n  1: required i32 id,\r\n  2: required string name,\r\n  3: required Map<string, string> props,\r\n  4: required i32 timestamp\r\n  5: optional i32 test\r\n}\r\n```\r\n\r\n\r\nRunning the tests\r\n=================\r\n\r\nphantom uses Embedded Cassandra to run tests without a local Cassandra server running.\r\nYou need two terminals to run the tests, one for Embedded Cassandra and one for the actual tests.\r\n\r\n```scala\r\nsbt\r\nproject phantom-cassandra-unit\r\nrun\r\n```\r\n\r\nThen in a new terminal\r\n\r\n```scala\r\nsbt\r\nproject phantom-test\r\ntest\r\n```\r\n\r\nMaintainers\r\n===========\r\n\r\nPhantom was developed at newzly as an in-house project.\r\nAll Cassandra integration at newzly goes through Phantom.\r\n\r\n- Sorin Chiprian sorin.chiprian@newzly.com\r\n- Flavian Alexandru flavian@newzly.com\r\n\r\nPre newzly fork\r\n===============\r\nSpecial thanks to Viktor Taranenko from WhiskLabs, who gave us the original idea.\r\n\r\nCopyright\r\n=========\r\nCopyright 2013 WhiskLabs, Copyright 2013 - 2014 newzly.\r\n\r\n\r\nContributions\r\n=============\r\n\r\nContributions are most welcome! \r\n\r\nTo contribute, simply submit a \"Pull request\" via GitHub.\r\n\r\nWe use GitFlow as a branching model and SemVer for versioning.\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}